{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..\\\\PythonModules\\\\'))                                           \n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "##import Bedrock_Client\n",
    "##import pyodbc\n",
    "import pandas as pd\n",
    "import PredictorOptimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##df = pd.read_sql_query('select * fROM ref.SHMI_Model_Predict_Statistics',Bedrock_Conn)\n",
    "import Pickle_Utility\n",
    "df =Pickle_Utility.read('shimi_predictor')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.to_csv('shmi_predictor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "PREDICTOR = 'Intercept'\n",
    "DIAGNOSIS_GROUP = '1'\n",
    "\n",
    "new_df = df[(df['PREDICTOR']==PREDICTOR)&(df['DIAGNOSIS_GROUP']==DIAGNOSIS_GROUP)][['Date','PARAMETER_ESTIMATE']].sort_values(by='Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PARAMETER_ESTIMATE</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-05-13</th>\n      <td>-4.7593</td>\n    </tr>\n    <tr>\n      <th>2019-06-13</th>\n      <td>-4.7471</td>\n    </tr>\n    <tr>\n      <th>2019-07-13</th>\n      <td>-4.6321</td>\n    </tr>\n    <tr>\n      <th>2019-08-13</th>\n      <td>-4.6613</td>\n    </tr>\n    <tr>\n      <th>2019-09-13</th>\n      <td>-4.4920</td>\n    </tr>\n    <tr>\n      <th>2019-10-13</th>\n      <td>-4.7900</td>\n    </tr>\n    <tr>\n      <th>2019-11-13</th>\n      <td>-4.6420</td>\n    </tr>\n    <tr>\n      <th>2019-12-13</th>\n      <td>-4.7312</td>\n    </tr>\n    <tr>\n      <th>2020-01-13</th>\n      <td>-4.8876</td>\n    </tr>\n    <tr>\n      <th>2020-02-13</th>\n      <td>-4.6399</td>\n    </tr>\n    <tr>\n      <th>2020-03-13</th>\n      <td>-4.4390</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "            PARAMETER_ESTIMATE\nDate                          \n2019-05-13             -4.7593\n2019-06-13             -4.7471\n2019-07-13             -4.6321\n2019-08-13             -4.6613\n2019-09-13             -4.4920\n2019-10-13             -4.7900\n2019-11-13             -4.6420\n2019-12-13             -4.7312\n2020-01-13             -4.8876\n2020-02-13             -4.6399\n2020-03-13             -4.4390"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AR\n",
    "from statsmodels.tsa.ar_model import ARResults\n",
    "import numpy\n",
    " \n",
    "# create a difference transform of the dataset\n",
    "def difference(dataset):\n",
    "    diff = list()\n",
    "    for i in range(1, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - 1]\n",
    "        diff.append(value)\n",
    "    return numpy.array(diff)\n",
    "df_train = new_df.drop(new_df.tail(1).index, inplace=False) \n",
    "# load dataset\n",
    "series = df_train.astype('float')\n",
    "X = difference(series.values)\n",
    "# fit model\n",
    "model = AR(X)\n",
    "model_fit = model.fit(maxlag=5, disp=False)\n",
    "# save model to file\n",
    "model_fit.save('ar_model.pkl')\n",
    "# save the differenced dataset\n",
    "numpy.save('ar_data.npy', X)\n",
    "# save the last ob\n",
    "numpy.save('ar_obs.npy', [series.values[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[ 0.0122]\n [ 0.115 ]\n [-0.0292]\n [ 0.1693]\n [-0.298 ]\n [ 0.148 ]\n [-0.0892]\n [-0.1564]\n [ 0.2477]]\n"
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[0.01326667]\n"
    }
   ],
   "source": [
    "print(sum(X)/len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[array([-4.6399])]"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[series.values[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[-0.0354333  -0.66667201  0.22065944  0.50854369 -0.34165519  0.12682167]\n[[-4.6399]]\n"
    }
   ],
   "source": [
    "# load the AR model from file\n",
    "from statsmodels.tsa.ar_model import ARResults\n",
    "import numpy\n",
    "loaded = ARResults.load('ar_model.pkl')\n",
    "print(loaded.params)\n",
    "data = numpy.load('ar_data.npy')\n",
    "last_ob = numpy.load('ar_obs.npy')\n",
    "print(last_ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Prediction: -5.008699\n"
    }
   ],
   "source": [
    "# load AR model from file and make a one-step prediction\n",
    "from statsmodels.tsa.ar_model import ARResults\n",
    "import numpy\n",
    "# load model\n",
    "model = ARResults.load('ar_model.pkl')\n",
    "data = numpy.load('ar_data.npy')\n",
    "last_ob = numpy.load('ar_obs.npy')\n",
    "# make prediction\n",
    "predictions = model.predict(start=len(data), end=len(data))\n",
    "# transform prediction\n",
    "yhat = predictions[0] + last_ob[0]\n",
    "print('Prediction: %f' % yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PARAMETER_ESTIMATE</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020-03-13</th>\n      <td>-4.439</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "           PARAMETER_ESTIMATE\nDate                         \n2020-03-13             -4.439"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "10   -4.841359\ndtype: float64\nf:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:219: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n  ' ignored when e.g. forecasting.', ValueWarning)\nf:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:576: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n  ValueWarning)\n"
    }
   ],
   "source": [
    "# AR example\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from random import random\n",
    "# contrived dataset\n",
    "data = df_train.astype('float')\n",
    "# fit model\n",
    "model = AR(data)\n",
    "model_fit = model.fit()\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(data), len(data))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "10   -4.64213\ndtype: float64\nf:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:219: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n  ' ignored when e.g. forecasting.', ValueWarning)\nf:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:576: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n  ValueWarning)\n"
    }
   ],
   "source": [
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from random import random\n",
    "# contrived dataset\n",
    "data = df_train.astype('float')\n",
    "# fit model\n",
    "model = SimpleExpSmoothing(data)\n",
    "model_fit = model.fit()\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(data), len(data))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "10   -4.64213\ndtype: float64\nf:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:219: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n  ' ignored when e.g. forecasting.', ValueWarning)\nf:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:576: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n  ValueWarning)\n"
    }
   ],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from random import random\n",
    "# contrived dataset\n",
    "data = df_train.astype('float')\n",
    "# fit model\n",
    "model = ExponentialSmoothing(data)\n",
    "model_fit = model.fit()\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(data), len(data))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PARAMETER_ESTIMATE</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-05-13</th>\n      <td>-4.7593</td>\n    </tr>\n    <tr>\n      <th>2019-06-13</th>\n      <td>-4.7471</td>\n    </tr>\n    <tr>\n      <th>2019-07-13</th>\n      <td>-4.6321</td>\n    </tr>\n    <tr>\n      <th>2019-08-13</th>\n      <td>-4.6613</td>\n    </tr>\n    <tr>\n      <th>2019-09-13</th>\n      <td>-4.4920</td>\n    </tr>\n    <tr>\n      <th>2019-10-13</th>\n      <td>-4.7900</td>\n    </tr>\n    <tr>\n      <th>2019-11-13</th>\n      <td>-4.6420</td>\n    </tr>\n    <tr>\n      <th>2019-12-13</th>\n      <td>-4.7312</td>\n    </tr>\n    <tr>\n      <th>2020-01-13</th>\n      <td>-4.8876</td>\n    </tr>\n    <tr>\n      <th>2020-02-13</th>\n      <td>-4.6399</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "            PARAMETER_ESTIMATE\nDate                          \n2019-05-13             -4.7593\n2019-06-13             -4.7471\n2019-07-13             -4.6321\n2019-08-13             -4.6613\n2019-09-13             -4.4920\n2019-10-13             -4.7900\n2019-11-13             -4.6420\n2019-12-13             -4.7312\n2020-01-13             -4.8876\n2020-02-13             -4.6399"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "> Model[['add', True, None, None, False, True]] 0.623\n > Model[['add', True, None, None, False, False]] 0.175\n > Model[['add', False, None, None, False, True]] 0.623\n > Model[['add', False, None, None, False, False]] 0.186\n > Model[[None, False, None, None, False, True]] 0.549\n > Model[[None, False, None, None, False, False]] 0.176\ndone\n['add', True, None, None, False, False] 0.1754870186730296\n[None, False, None, None, False, False] 0.17629251659641273\n['add', False, None, None, False, False] 0.1857730899070298\n"
    }
   ],
   "source": [
    "data = df_train.astype('float').values\n",
    "\t# data split\n",
    "n_test = 3\n",
    "# model configs\n",
    "cfg_list = PredictorOptimize.exp_smoothing_configs(seasonal=[None])\n",
    "# grid search\n",
    "\n",
    "#walk_forward_validation(data, n_test, cfg)\n",
    "\n",
    "scores = PredictorOptimize.grid_search(data[:,0], cfg_list, n_test)\n",
    "print('done')\n",
    "# list top 3 configs\n",
    "for cfg, error in scores[:3]:\n",
    "    print(cfg, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "> Model[['add', True, None, None, False, True]] 0.737\n > Model[['add', True, None, None, False, False]] 0.225\n > Model[['add', False, None, None, False, True]] 0.738\n > Model[['add', False, None, None, False, False]] 0.237\n > Model[[None, False, None, None, False, True]] 0.680\n > Model[[None, False, None, None, False, False]] 0.226\ndone\n['add', True, None, None, False, False] 0.2249471841412778\n[None, False, None, None, False, False] 0.22588994854105948\n['add', False, None, None, False, False] 0.2370129759551018\n"
    }
   ],
   "source": [
    "data = new_df.astype('float').values\n",
    "\t# data split\n",
    "n_test = 3\n",
    "# model configs\n",
    "cfg_list = PredictorOptimize.exp_smoothing_configs(seasonal=[None])\n",
    "# grid search\n",
    "\n",
    "#walk_forward_validation(data, n_test, cfg)\n",
    "\n",
    "scores = PredictorOptimize.grid_search(data[:,0], cfg_list, n_test)\n",
    "print('done')\n",
    "# list top 3 configs\n",
    "for cfg, error in scores[:3]:\n",
    "    print(cfg, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([-4.69825])"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data)/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "-4.642129807658069"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PredictorOptimize.exp_smoothing_forecast(data, ['additive', True, 2, None, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-4.7593],\n       [-4.7471],\n       [-4.6321],\n       [-4.6613],\n       [-4.492 ],\n       [-4.79  ],\n       [-4.642 ],\n       [-4.7312],\n       [-4.8876],\n       [-4.6399],\n       [-4.439 ]])"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PARAMETER_ESTIMATE</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-05-13</th>\n      <td>-4.7593</td>\n    </tr>\n    <tr>\n      <th>2019-06-13</th>\n      <td>-4.7471</td>\n    </tr>\n    <tr>\n      <th>2019-07-13</th>\n      <td>-4.6321</td>\n    </tr>\n    <tr>\n      <th>2019-08-13</th>\n      <td>-4.6613</td>\n    </tr>\n    <tr>\n      <th>2019-09-13</th>\n      <td>-4.492</td>\n    </tr>\n    <tr>\n      <th>2019-10-13</th>\n      <td>-4.79</td>\n    </tr>\n    <tr>\n      <th>2019-11-13</th>\n      <td>-4.642</td>\n    </tr>\n    <tr>\n      <th>2019-12-13</th>\n      <td>-4.7312</td>\n    </tr>\n    <tr>\n      <th>2020-01-13</th>\n      <td>-4.8876</td>\n    </tr>\n    <tr>\n      <th>2020-02-13</th>\n      <td>-4.6399</td>\n    </tr>\n    <tr>\n      <th>2020-03-13</th>\n      <td>-4.439</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "           PARAMETER_ESTIMATE\nDate                         \n2019-05-13            -4.7593\n2019-06-13            -4.7471\n2019-07-13            -4.6321\n2019-08-13            -4.6613\n2019-09-13             -4.492\n2019-10-13              -4.79\n2019-11-13             -4.642\n2019-12-13            -4.7312\n2020-01-13            -4.8876\n2020-02-13            -4.6399\n2020-03-13             -4.439"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-4.7593    ],\n       [-4.7471    ],\n       [-4.6321    ],\n       [-4.6613    ],\n       [-4.492     ],\n       [-4.79      ],\n       [-4.642     ],\n       [-4.7312    ],\n       [-4.8876    ],\n       [-4.6399    ],\n       [-4.439     ],\n       [-4.44037225]])"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "b=np.array([[PredictorOptimize.exp_smoothing_forecast(data, ['add', True, None, None, False, False])]])\n",
    "data = np.concatenate((data, b))\n",
    "#add([exp_smoothing_forecast(data, ['add', True, None, None, False, False])])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "-4.44037224892244"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PredictorOptimize.exp_smoothing_forecast(data, ['add', True, None, None, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "\"['add', True, None, None, False, False]\""
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = scores[:1][0][0]\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 3\n",
    "def predict_n_steps(data, n_steps, use_new_model = True):\n",
    "    data_history = data\n",
    "    cfg_list = PredictorOptimize.exp_smoothing_configs(seasonal=[0,6,12])\n",
    "    scores = PredictorOptimize.grid_search(data[:,0], cfg_list, n_test)\n",
    "    config = scores[:1][0][0]\n",
    "    if use_new_model == True:\n",
    "        for i in range(n_steps):\n",
    "            new = np.array([[PredictorOptimize.exp_smoothing_forecast(data_history,ast.literal_eval(config))]])\n",
    "            data_history = np.concatenate((data_history, new))\n",
    "    else:\n",
    "        t,d,s,p,b,r = ast.literal_eval(config)\n",
    "        model = ExponentialSmoothing(data_history, trend=t, damped=d, seasonal=s, seasonal_periods=p)\n",
    "        model_fit = model.fit(optimized=True, use_boxcox=b, remove_bias=r)\n",
    "        for i in range(n_steps):            \n",
    "            yhat = np.array([model_fit.predict(len(data_history), len(data_history))])            \n",
    "            data_history = np.concatenate((data_history, yhat))            \n",
    "    return data_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "> Model[['add', True, None, 0, False, True]] 0.653\n > Model[['add', True, None, 0, False, False]] 0.205\n > Model[['add', True, None, 6, False, True]] 0.653\n > Model[['add', True, None, 6, False, False]] 0.205\n > Model[['add', True, None, 12, False, True]] 0.653\n > Model[['add', True, None, 12, False, False]] 0.205\n > Model[['add', False, None, 0, False, True]] 0.653\n > Model[['add', False, None, 0, False, False]] 0.214\n > Model[['add', False, None, 6, False, True]] 0.653\n > Model[['add', False, None, 6, False, False]] 0.214\n > Model[['add', False, None, 12, False, True]] 0.653\n > Model[['add', False, None, 12, False, False]] 0.214\n > Model[[None, False, 'add', 6, False, True]] 0.566\n > Model[[None, False, 'add', 6, False, False]] 0.659\n > Model[[None, False, None, 0, False, True]] 0.594\n > Model[[None, False, None, 0, False, False]] 0.206\n > Model[[None, False, None, 6, False, True]] 0.594\n > Model[[None, False, None, 6, False, False]] 0.206\n > Model[[None, False, None, 12, False, True]] 0.594\n > Model[[None, False, None, 12, False, False]] 0.206\nf:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters.py:711: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n  ConvergenceWarning)\nf:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters.py:711: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n  ConvergenceWarning)\n"
    },
    {
     "data": {
      "text/plain": "array([[-4.7593    ],\n       [-4.7471    ],\n       [-4.6321    ],\n       [-4.6613    ],\n       [-4.492     ],\n       [-4.79      ],\n       [-4.642     ],\n       [-4.7312    ],\n       [-4.8876    ],\n       [-4.6399    ],\n       [-4.439     ],\n       [-4.44037225],\n       [-4.44037225],\n       [-2.9632595 ],\n       [-3.0162364 ]])"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_n_steps(data,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "> Model[['add', True, None, 0, False, True]] 0.653\n > Model[['add', True, None, 0, False, False]] 0.205\n > Model[['add', True, None, 6, False, True]] 0.653\n > Model[['add', True, None, 6, False, False]] 0.205\n > Model[['add', True, None, 12, False, True]] 0.653\n > Model[['add', True, None, 12, False, False]] 0.205\n > Model[['add', False, None, 0, False, True]] 0.653\n > Model[['add', False, None, 0, False, False]] 0.214\n > Model[['add', False, None, 6, False, True]] 0.653\n > Model[['add', False, None, 6, False, False]] 0.214\n > Model[['add', False, None, 12, False, True]] 0.653\n > Model[['add', False, None, 12, False, False]] 0.214\n > Model[[None, False, 'add', 6, False, True]] 0.566\n > Model[[None, False, 'add', 6, False, False]] 0.659\n > Model[[None, False, None, 0, False, True]] 0.594\n > Model[[None, False, None, 0, False, False]] 0.206\n > Model[[None, False, None, 6, False, True]] 0.594\n > Model[[None, False, None, 6, False, False]] 0.206\n > Model[[None, False, None, 12, False, True]] 0.594\n > Model[[None, False, None, 12, False, False]] 0.206\n"
    },
    {
     "data": {
      "text/plain": "array([[-4.7593    ],\n       [-4.7471    ],\n       [-4.6321    ],\n       [-4.6613    ],\n       [-4.492     ],\n       [-4.79      ],\n       [-4.642     ],\n       [-4.7312    ],\n       [-4.8876    ],\n       [-4.6399    ],\n       [-4.439     ],\n       [-4.44037225],\n       [-4.44037225],\n       [-4.44037225],\n       [-4.44037225]])"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_n_steps(data,4,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}